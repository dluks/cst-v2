version: "2"
project_root: "../../.."
product_dir: "pipeline/products/hyd_cwm_stg_no-xf_1km"
trait_type: "hydraulic"
product_code: "hyd_cwm_stg_no-xf_1km"

# Container configuration
container:
  type: "singularity"  # "singularity" or "docker"
  name: "cit-sci-traits"
  docker_tag: "latest"
  def: "cit-sci-traits.def"
  image: "cit-sci-traits.sif"

model_res: "1km"
PFT: "Shrub_Tree_Grass"
random_seed: 42
base_resolution: 1000 # Shared best resolution of all EO datasets (used for masking)
target_resolution: 1000 # Target resolution for model training
extent: [-180, -90, 180, 90] # Extent of the final dataset
crs: "EPSG:6933" # Equal Area Cylindrical projection
tmp_dir: tmp/hyd_cwm_stg_no-xf_1km
raw_dir: data/raw
interim_dir: data/interim
processed_dir: data/processed
dask_dashboard: ":39143"
trait_mapping: "reference/trait_mapping.json"
trait_stat_mapping: "reference/trait_stat_mapping.json"
try_version: 6
splot_open: false

nemo:
  build_gbif_maps:
    n_workers: 60 # 80 was throwing too many files open error...
    threads_per_worker: 4
    memory_limit: 15GB
  build_splot_maps:
    npartitions: 60
    dask:
      n_workers: 40
      threads_per_worker: 5
      memory_limit: 40GB
  merge_y_traits:
    n_workers: 8
    memory_limit: 100GB
    threads_per_worker: 2
  calc_spatial_autocorr:
    n_workers: 4
    n_chunks: 24 # x direction only

mask:
  path: data/raw/esa_worldcover_v100_1km/esa_worldcover_v100_1km.tif
  keep_classes:
    - 10 # Tree cover
    - 20 # Shrubland
    - 30 # Grassland
    - 40 # Cropland
    - 60 # Bare/sparse vegetation
    - 70 # Snow and ice
    - 90 # Herbaceous wetland
    - 95 # Mangroves
    - 100 # Moss and lichen

datasets:
  X:
    canopy_height: ETH_GlobalCanopyHeight_2020_v1_1km
    modis: modis_sur_refl_monthly_avg_1km
    soilgrids: soilgrids_v2-0_1km
    vodca: vodca_mean-p5-p95_1km
    worldclim: wc2-1_30s_bio
  Y:
    fd_mode: false
    trait_stats: ["mean", "std", "median", "q02", "q05", "q25", "q75", "q95", "q98", "count"]  # non-FD metrics
    # trait_stats: ["f_ric", "f_eve", "f_div", "sp_ric"]  # FD metrics
    trait_stat: 1 # (bands start at 1) - index 1 = "mean" (cwm)
    correlation_fn: splot_gbif_correlation.csv

eo_data:
  interim:
    dir: eo_data
  predict:
    dir: predict
    mask_fn: eo_predict_mask.parquet
    imputed_fn: eo_predict_imputed.parquet

traits:
  raw: data/raw/hydraulic_traits_knighton/GlobalTrees_Traits_Median.xlsx
  sheet: GlobalTraits_Median
  names:
    - gsmax
    - P12
    - P50
    - P88
    - rdmax
    - WUE
  transform: null
  pfts: data/raw/try_pfts.parquet
  pfts_threshold: 0.60
  harmonization_fp: data/raw/hydraulic_traits_matching_results_2025-10-03.gz
  interim_out: data/interim/traits/hydraulic_no-xf/hydraulic_no-xf.parquet
  trait_map_layers: ["mean", "std", "median", "q02", "q05", "q25", "q75", "q95", "q98", "count", "count_weighted"]
  target_trait_stat: "mean"
  # Power transformation settings (disabled for hydraulic traits)
  power_transform: false  # Disable Yeo-Johnson power transformation
  transform_method: "yeo-johnson"  # Transformation method (not used when power_transform=false)
  transformer_dir: "data/features/hyd_cwm_stg_no-xf_1km/y_data/transformers"  # Directory to save transformers
  # Reliability weighting settings
  use_reliability_weights: true  # Enable reliability weighting based on count_weighted
  reliability_transform: "sqrt"  # Transform count_weighted using sqrt before creating reliability weights
  reliability_min: 0.1  # Minimum reliability weight (for normalization)
  reliability_max: 1.0  # Maximum reliability weight (for normalization)


gbif:
  maps_dir: data/interim/gbif/maps/hyd_stg_no-xf_1km
  min_count: 10

splot:
  maps_dir: data/interim/splot/maps/hyd_stg_no-xf_1km

trydb:
  raw:
    try6:
      dir: TRY_6_gapfilled_for_distribution
      zip: TRY6_gapfilled_for_distribution.zip
      zipfile_csv: TRY6_gapfilled_for_distribution/TRY6_gapfilled_filtered_2.csv.zip
    try5:
      dir: TRY_5_GapFilledData_2020
      zip: TRY_5_GapFilledData_2020.zip
      zipfile_csv: TRY_50_2020_01/gapfilled_data/mean_gap_filled_back_transformed_incl_species_names.csv
    pfts: try_pft_v2.parquet
  interim:
    dir: try
    quantile_range: null  # Use [0.005, 0.995] for TRY5. No filtering needed for TRY6
    transform: null # "log", "power" (yeo-johnson), null (no transformation) - NOTE: For hydraulic traits, see traits.transform instead
    already_norm: null
    filtered: traits.parquet
    perform_pca: false # This will reduce the number of traits by projecting them onto the principal components
    pca_n_components: 4 # Fraction of variance to keep. If integer, this is the number of components.
    pca_fn: no_pca.pkl # Set to no_pca.pkl if perform_pca is false

biomes: # Used for model analysis by biome
  reclassification:
    1: 1  # Tropical/Subtropical Forests
    2: 1
    3: 1
    4: 2  # Temperate/Boreal Forests
    5: 2
    6: 2
    7: 3  # Grasslands and Savannas
    8: 3
    12: 4 # Mediterranean
    13: 5  # Deserts
    9: 6  # Wetlands
    14: 6
    98: 6
    10: 7  # Alpine/Polar
    11: 7
    99: 7
  raw_path: wwf_terr_biomes/wwf_terr_biomes.tif # Relative to raw_dir
  interim_path: biomes/biomes.tif # Relative to interim_dir

spatial_autocorr:
  ranges_fp: data/features/hyd_cwm_stg_no-xf_1km/spatial_autocorr.parquet

train:
  dir: data/features
  Y:
    fn: Y.parquet
    fp: data/features/hyd_cwm_stg_no-xf_1km/y_data/Y.parquet  # Full path to Y file
  xy_data:
    fn: xy_all_traits.parquet
    fp: data/features/hyd_cwm_stg_no-xf_1km/xy_data/xy_all_traits.parquet  # Full path to merged XY data
  predict:
    fp: data/features/predict/modis_wc2_soil_canopy_vodca_alos_1km/X.parquet
  missing_val_thresh: 0.4 # Drop features with more than this fraction of missing values
  trait_sets: ["splot_gbif"]
  spatial_autocorr: spatial_autocorr.parquet
  cv_splits:
    # Spatial autocorrelation range configuration
    # Option 1: Use custom range (highest priority, overrides all other settings)
    custom_range: 700000  # Set to a value in meters (e.g., 600000 for 600 km) to use fixed range for all traits
    # Option 2: Use statistics from spatial_autocorr.parquet
    range_mode: "all_traits"  # "per_trait" or "all_traits"
    per_trait_stat: "mean"   # Which column from spatial_autocorr.parquet to use (mean, median, q05, q95, std)
    all_traits_aggregation: "min"  # For all_traits mode: how to aggregate stat across traits (mean, median, min, max)
    # Deprecated (kept for backward compatibility):
    range_stat: "mean"
    # CV split parameters
    n_splits: 6
    n_sims: 200
    balance_weight: 0  # Weight for sample count balance in fold assignment (0.0=only count balance, 1.0=only KS test, 0.5=equal)
    dir: skcv_splits
    dir_fp: data/features/hyd_cwm_stg_no-xf_1km/skcv_splits  # Full path to CV splits directory
  weights:
    fn: feature_weights.parquet
    method: auto # "auto", "manual" -- "manual" will use below weights
    splot: 1.0
    gbif: 0.08661
  arch: "autogluon"
  eval_results: evaluation_results.csv
  feature_importance: feature_importance.csv

processed:
  dir: data/processed
  predict_dir: predict
  aoa_dir: aoa
  cov_dir: cov
  splot_corr: splot_correlation.csv

autogluon:
  included_model_types: ["GBM", "CAT"]
  excluded_model_types: null # ["KNN", "RF", "XT", "NN_TORCH"]
  presets: ["medium"] # Set to null to determine preset based on training set size
  dynamic_stacking: true
  num_bag_folds: null
  num_stack_levels: null
  save_bag_folds: true
  refit_full: false
  set_best_to_refit_full: false
  cv_fit_time_limit: 1 # Hours
  full_fit_time_limit: 1 # Hours
  feature_importance: true
  FI_time_limit: 0.5 # Hours
  FI_num_shuffle_sets: 10

models:
  dir: models
  dir_fp: models/hyd_cwm_stg_no-xf_1km  # Full path to models directory

aoa:
  dir: aoa

predict:
  dir: predict
  geos:
    n_workers: 1
    batches: 8
  pylos:
    n_workers: 1
    batches: 24

cov:
  dir: cov

public:
  destination: "both"
  local_dir: final
  sftp_dir: PANOPS/cit-sci-traits/trait_maps

analysis:
  dir: results
  multires_results_fn: all_results.parquet
  multires_fi_fn: all_fi.parquet
