version: "2"
project_root: "../../.."
product_dir: "pipeline/products/try6_q95_stg_pow-xf_1km"
trait_type: "try6"
product_code: "try6_q95_stg_pow-xf_1km"

# Container configuration
container:
  type: "singularity"  # "singularity" or "docker"
  name: "cit-sci-traits"
  docker_tag: "latest"
  def: "cit-sci-traits.def"
  image: "cit-sci-traits.sif"

model_res: "1km"
PFT: "Shrub_Tree_Grass"
random_seed: 42
base_resolution: 1000 # Shared best resolution of all EO datasets (used for masking)
target_resolution: 1000 # Target resolution for model training
extent: [-180, -90, 180, 90] # Extent of the final dataset
crs: "EPSG:6933" # Equal Area Cylindrical projection
tmp_dir: tmp/try6_q95_stg_pow-xf_1km
raw_dir: data/raw
interim_dir: data/interim
processed_dir: data/processed
dask_dashboard: ":39143"
trait_mapping: "reference/trait_mapping.json"
trait_stat_mapping: "reference/trait_stat_mapping.json"
try_version: 6
splot_open: false

old_sycfgs:
  pylos:
    "1km":
      harmonize_eo_data:
        n_workers: 12
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 20
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 20
          memory_limit: 40GB
      featurize_train:
        n_chunks: 6
        n_workers: 30
        memory_limit: null
        threads_per_worker: 2
      build_predict:
        n_chunks: 5
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 3
      calc_spatial_autocorr:
        n_workers: 60
        n_workers_variogram: 5
        n_chunks: 4
      skcv_splits:
        n_workers: 60
      aoa:
        device_ids: [0, 1]
        predict_sample: 0.5
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: true
          train_sample: 0.5
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "001":
      harmonize_eo_data:
        n_workers: 12
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 40
          memory_limit: 40GB
      featurize_train:
        n_chunks: 6
        n_workers: 30
        memory_limit: null
        threads_per_worker: 5
      build_predict:
        n_chunks: 5
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 3
      calc_spatial_autocorr:
        n_workers: 60
        n_workers_variogram: 5
        n_chunks: 4
      skcv_splits:
        n_workers: 60
      aoa:
        device_ids: [0, 1]
        predict_sample: 0.5
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: true
          train_sample: 0.5
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 3
        threads_per_worker: 1
    "22km":
      harmonize_eo_data:
        n_workers: 20
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 60
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 60
        memory_limit: null
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 60
        n_workers_variogram: 5
        n_chunks: 4
      skcv_splits:
        n_workers: 60
      aoa:
        device_ids: [0, 1]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "02":
      harmonize_eo_data:
        n_workers: 20
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 60
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 60
        memory_limit: null
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 60
        n_workers_variogram: 5
        n_chunks: 4
      skcv_splits:
        n_workers: 60
      aoa:
        device_ids: [0, 1]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "05":
      harmonize_eo_data:
        n_workers: 18
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 60
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 60
        memory_limit: null
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 60
        n_workers_variogram: 60
        n_chunks: 4
      skcv_splits:
        n_workers: 60
      aoa:
        device_ids: [0, 1]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "1":
      harmonize_eo_data:
        n_workers: 48
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 60
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 30
        memory_limit: null
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 60
        n_workers_variogram: 5
        n_chunks: 4
      skcv_splits:
        n_workers: 60
      aoa:
        device_ids: [0, 1]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "2":
      harmonize_eo_data:
        n_workers: 30
      match_gbif_pfts:
        n_workers: 80
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 30
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 30
        memory_limit: null
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: null
        memory_limit: 100GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 20
        n_workers_variogram: 5
        n_chunks: 4
      skcv_splits:
        n_workers: 30
      aoa:
        device_ids: [0, 1]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
  geos:
    "1km":
      harmonize_eo_data:
        n_workers: 48
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_workers: 60 # 80 was throwing too many files open error...
        threads_per_worker: 5
        memory_limit: 15GB
      build_splot_maps:
        npartitions: 60  
        dask:
          n_workers: 40
          threads_per_worker: 5
          memory_limit: 40GB
      featurize_train:
        n_chunks: 4
        n_workers: 8
        memory_limit: 100GB
        threads_per_worker: 2
      build_predict:
        n_chunks: 3
        n_workers: 80
        memory_limit: 400GB
        impute_chunks: 2
      calc_spatial_autocorr:
        n_workers: 1
        n_workers_variogram: 20  # For WGS84 coords only
        n_chunks: 12 # x direction only
        gpu_ids: [0, 1]
      skcv_splits:
        n_workers: 50
        threads_per_worker: 1
      aoa:
        device_ids: [0, 1]
        predict_sample: 0.5
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: true
          train_sample: 0.5
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "001":
      harmonize_eo_data:
        n_workers: 48
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60
        dask:
          n_workers: 60
          memory_limit: 40GB
      featurize_train:
        n_chunks: 2
        n_workers: 100
        memory_limit: 150GB
        threads_per_worker: 5
      build_predict:
        n_chunks: 3
        n_workers: 100
        memory_limit: 500GB
        impute_chunks: 2
      calc_spatial_autocorr:
        n_workers: 100
        n_workers_variogram: 20
        n_chunks: 4
      skcv_splits:
        n_workers: 80
      aoa:
        device_ids: [0, 1, 2, 3]
        predict_sample: 0.5
        splot:
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: true
          train_sample: 0.5
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "22km":
      harmonize_eo_data:
        n_workers: 20
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_partitions: null
        n_workers: 40 # 80 was throwing too many files open error...
        threads_per_worker: 4
        memory_limit: 40GB
      build_splot_maps:
        npartitions: 40
        dask:
          n_workers: 40
          threads_per_worker: 4
          memory_limit: 40GB
      featurize_train:
        n_chunks: 10
        n_workers: 8
        memory_limit: 150GB
        threads_per_worker: 1
      build_predict:
        n_chunks: 3
        n_workers: 80
        memory_limit: 400GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 3
        n_workers_variogram: 20  # For WGS84 coords only
        n_chunks: 16 # x direction only
      skcv_splits:
        n_workers: 50
        threads_per_worker: 1
      aoa:
        device_ids: [1, 2, 3]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: true
          train_sample: 1
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "02":
      harmonize_eo_data:
        n_workers: 48
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 80
        dask:
          n_workers: 80
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 100
        memory_limit: 150GB
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: 100
        memory_limit: 500GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 100
        n_workers_variogram: 20
        n_chunks: 4
      skcv_splits:
        n_workers: 80
      aoa:
        device_ids: [0, 1, 2, 3]
        predict_sample: 0.5
        splot:
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 0.5
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "55km":
      harmonize_eo_data:
        n_workers: 20
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_partitions: null
        n_workers: 10 # 80 was throwing too many files open error...
        threads_per_worker: 4
        memory_limit: 30GB
      build_splot_maps:
        npartitions: 40
        dask:
          n_workers: 40
          threads_per_worker: 4
          memory_limit: 40GB
      featurize_train:
        n_chunks: 10
        n_workers: 8
        memory_limit: 150GB
        threads_per_worker: 1
      build_predict:
        n_chunks: 3
        n_workers: 80
        memory_limit: 400GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 3
        n_workers_variogram: 20  # For WGS84 coords only
        n_chunks: 16 # x direction only
      skcv_splits:
        n_workers: 50
        threads_per_worker: 1
      aoa:
        device_ids: [1, 2, 3]
        predict_sample: 1
        splot:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: true
          train_sample: 1
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "05":
      harmonize_eo_data:
        n_workers: 48
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 80
        dask:
          n_workers: 80
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 100
        memory_limit: 150GB
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: 100
        memory_limit: 500GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 100
        n_workers_variogram: 20
        n_chunks: 4
      skcv_splits:
        n_workers: 80
      aoa:
        device_ids: [0, 1, 2, 3]
        predict_sample: 0.5
        splot:
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 0.5
          avg_dist_batch_size: 5000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "1":
      harmonize_eo_data:
        n_workers: 80
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 60  
        dask:
          n_workers: 40
          threads_per_worker: 5
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 100
        memory_limit: 150GB
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: 100
        memory_limit: 500GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 100
        n_workers_variogram: 40
        n_chunks: 4
      skcv_splits:
        n_workers: 80
      aoa:
        device_ids: [0, 1, 2, 3]
        predict_sample: 0.5
        splot:
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
    "2":
      harmonize_eo_data:
        n_workers: 80
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_workers: 50
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 80
        dask:
          n_workers: 80
          memory_limit: 40GB
      featurize_train:
        n_chunks: 1
        n_workers: 100
        memory_limit: 150GB
        threads_per_worker: 5
      build_predict:
        n_chunks: 1
        n_workers: 100
        memory_limit: 500GB
        impute_chunks: 1
      calc_spatial_autocorr:
        n_workers: 100
        n_workers_variogram: 40
        n_chunks: 4
      skcv_splits:
        n_workers: 80
      aoa:
        device_ids: [0, 1, 2, 3]
        predict_sample: 0.5
        splot:
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
        splot_gbif:
          chunked_dist: false
          train_sample: 1
          avg_dist_batch_size: 10000
          predict_partitions: null
      build_final_product:
        n_workers: 5
        threads_per_worker: 1
  nemo2:
    "1km":
      match_gbif_pfts:
        n_workers: 60
      build_gbif_maps:
        n_workers: 32
        threads_per_worker: 5
      build_splot_maps:
        npartitions: 80  
        dask:
          n_workers: 80
          threads_per_worker: 5
          memory_limit: 40GB
      featurize_train:
        n_chunks: 4
        n_workers: 8
        memory_limit: 100GB
        threads_per_worker: 2
      calc_spatial_autocorr:
        n_workers: 1
        n_workers_variogram: 20  # For WGS84 coords only
        n_chunks: 16 # x direction only
        gpu_ids: [0, 1, 2, 3]
    "55km":
      match_gbif_pfts:
        n_workers: 60
        n_partitions: 80
      build_gbif_maps:
        n_partitions: null
        n_workers: 40 # 80 was throwing too many files open error...
        threads_per_worker: 4
        memory_limit: 40GB
      build_splot_maps:
        npartitions: 40
        dask:
          n_workers: 40
          threads_per_worker: 4
          memory_limit: 40GB
      featurize_train:
        n_chunks: 10
        n_workers: 8
        memory_limit: 150GB
        threads_per_worker: 1

geos:
  calc_spatial_autocorr:
    n_workers: 3
    n_workers_variogram: 20  # For WGS84 coords only
    n_chunks: 16 # x direction only
    gpu_ids: [1, 2]
nemo:
  build_gbif_maps:
    n_workers: 60 # 80 was throwing too many files open error...
    threads_per_worker: 4
    memory_limit: 15GB
  build_splot_maps:
    npartitions: 60  
    dask:
      n_workers: 40
      threads_per_worker: 5
      memory_limit: 40GB
  merge_y_traits:
    n_workers: 8
    memory_limit: 100GB
    threads_per_worker: 2
  calc_spatial_autocorr:
    n_workers: 4
    n_chunks: 24 # x direction only

datasets:
  X:
    canopy_height: ETH_GlobalCanopyHeight_2020_v1_1km
    modis: modis_sur_refl_monthly_avg_1km
    soilgrids: soilgrids_v2-0_1km
    vodca: vodca_mean-p5-p95_1km
    worldclim: wc2-1_30s_bio
  Y:
    fd_mode: false
    trait_stats: ["mean", "std", "median", "q95", "q95", "count"]  # non-FD metrics
    # trait_stats: ["f_ric", "f_eve", "f_div", "sp_ric"]  # FD metrics
    trait_stat: 1 # (bands start at 1, FD metrics contain only (metric, 'count')
    correlation_fn: splot_gbif_correlation.csv

eo_data:
  interim:
    dir: eo_data
  predict:
    dir: predict
    mask_fn: eo_predict_mask.parquet
    imputed_fn: eo_predict_imputed.parquet

traits:
  # raw: data/raw/hydraulic_traits_knighton/GlobalTrees_Traits_Median.xlsx
  # sheet: GlobalTraits_Median
  names:
    - X4 # Stem specific density (SSD, stem dry mass per stem fresh volume) or wood density
    - X6 # Root rooting depth
    - X13 # Leaf carbon (C) content per leaf dry mass
    - X14 # Leaf nitrogen (N) content per leaf dry mass
    - X15 # Leaf phosphorus (P) content per leaf dry mass
    # - X21 # Stem diameter
    # - X26 # Seed dry mass
    # - X27 # Seed length
    - X46 # Leaf thickness
    # - X47 # Leaf dry mass per leaf fresh mass (leaf dry matter content, LDMC)
    - X50 # Leaf nitrogen (N) content per leaf area
    - X55 # Leaf dry mass (single leaf)
    - X78 # Leaf nitrogen (N) isotope signature (delta 15N)
    # - X95 # Seed germination rate (germination efficiency)
    - X138 # Seed number per reproducton unit
    # - X144 # Leaf length
    - X145 # Leaf width
    - X146 # Leaf carbon/nitrogen (C/N) ratio
    # - X163 # Leaf fresh mass
    - X169 # Stem conduit density (vessels and tracheids)
    - X237 # Dispersal unit length
    - X281 # Stem conduit diameter (vessels, tracheids)
    # - X282 # Wood vessel element length; stem conduit (vessel and tracheids) element length
    # - X289 # Wood fiber lengths
    # - X297 # Wood rays per millimetre (wood ray density)
    # - X614 # Fine root length per fine root dry mass (specific fine root length, SRL)
    # - X1080 # Root length per root dry mass (specific root length, SRL)
    # - X3106 # Plant height vegetative
    - X3114 # Leaf area (in case of compound leaves undefined if leaf or leaflet, undefined if petiole is in- or e
    - X3117 # Leaf area per leaf dry mass (specific leaf area, SLA or 1/LMA): undefined if petiole is in- or exclu
    # - X3120 # Leaf water content per leaf dry mass (not saturated)
  # transform: null
  # pfts: data/raw/try_pfts.parquet
  # pfts_threshold: 0.60
  # harmonization_fp: data/raw/hydraulic_traits_matching_results_2025-10-03.gz
  # interim_out: data/interim/traits/try6_no-xf/try6_no-xf.parquet
  trait_map_layers: ["mean", "std", "median", "q02","q05", "q95", "q98", "count", "count_weighted"]
  target_trait_stat: "q95"
  # Power transformation settings
  power_transform: true  # Enable Yeo-Johnson power transformation
  transform_method: "yeo-johnson"  # Transformation method
  transformer_dir: "data/features/try6_q95_stg_pow-xf_1km/y_data/transformers"  # Directory to save transformers
  # Reliability weighting settings
  use_reliability_weights: true  # Enable reliability weighting based on count_weighted
  reliability_transform: "sqrt"  # Transform count_weighted using sqrt before creating reliability weights
  reliability_min: 0.1  # Minimum reliability weight (for normalization)
  reliability_max: 1.0  # Maximum reliability weight (for normalization)


gbif:
  maps_dir: data/interim/gbif/maps/try6_stg_no-xf_1km

splot:
  maps_dir: data/interim/splot/maps/try6_stg_no-xf_1km

# trydb:
#   interim:
#     dir: try
    # quantile_range: null  # Use [0.005, 0.995] for TRY5. No filtering needed for TRY6
    # transform: power # "log", "power" (yeo-johnson), null (no transformation)
    # already_norm: null
    # filtered: traits.parquet
    # transformer_fn: power_transformer.pkl
    # perform_pca: false # This will reduce the number of traits by projecting them onto the principal components
    # pca_n_components: 4 # Fraction of variance to keep. If integer, this is the number of components.
    # pca_fn: no_pca.pkl # Set to no_pca.pkl if perform_pca is false

# biomes: # Used for model analysis by biome
#   reclassification:
#     1: 1  # Tropical/Subtropical Forests
#     2: 1
#     3: 1
#     4: 2  # Temperate/Boreal Forests
#     5: 2
#     6: 2
#     7: 3  # Grasslands and Savannas
#     8: 3
#     12: 4 # Mediterranean
#     13: 5  # Deserts
#     9: 6  # Wetlands
#     14: 6  
#     98: 6
#     10: 7  # Alpine/Polar
#     11: 7
#     99: 7
#   raw_path: wwf_terr_biomes/wwf_terr_biomes.tif # Relative to raw_dir
#   interim_path: biomes/biomes.tif # Relative to interim_dir
  
spatial_autocorr:
  ranges_fp: data/features/try6_q95_stg_pow-xf_1km/spatial_autocorr.parquet

train:
  dir: data/features
  Y:
    fn: Y.parquet
    fp: data/features/try6_q95_stg_pow-xf_1km/y_data/Y.parquet  # Full path to Y file
  xy_data:
    fn: xy_all_traits.parquet
    fp: data/features/try6_q95_stg_pow-xf_1km/xy_data/xy_all_traits.parquet  # Full path to merged XY data
  predict:
    fp: data/features/predict/modis_wc2_soil_canopy_vodca_alos_1km/X.parquet
  missing_val_thresh: 0.4 # Drop features with more than this fraction of missing values
  trait_sets: ["splot_gbif"]
  spatial_autocorr: spatial_autocorr.parquet
  cv_splits:
    # Spatial autocorrelation range configuration
    # Option 1: Use custom range (highest priority, overrides all other settings)
    custom_range: 700000  # Set to a value in meters (e.g., 600000 for 600 km) to use fixed range for all traits
    # Option 2: Use statistics from spatial_autocorr.parquet
    range_mode: "all_traits"  # "per_trait" or "all_traits"
    per_trait_stat: "mean"   # Which column from spatial_autocorr.parquet to use (mean, median, q95, q95, std)
    all_traits_aggregation: "min"  # For all_traits mode: how to aggregate stat across traits (mean, median, min, max)
    # Deprecated (kept for backward compatibility):
    range_stat: "mean"
    # CV split parameters
    n_splits: 6
    n_sims: 200
    balance_weight: 0  # Weight for sample count balance in fold assignment (0.0=only count balance, 1.0=only KS test, 0.5=equal)
    dir: skcv_splits
    dir_fp: data/features/try6_q95_stg_pow-xf_1km/skcv_splits  # Full path to CV splits directory
  weights:
    fn: feature_weights.parquet
    method: auto # "auto", "manual" -- "manual" will use below weights
    splot: 1.0
    gbif: 0.08661
  arch: "autogluon"
  eval_results: evaluation_results.csv
  feature_importance: feature_importance.csv

processed:
  dir: data/processed
  predict_dir: predict
  aoa_dir: aoa
  cov_dir: cov
  splot_corr: splot_correlation.csv

autogluon:
  included_model_types: ["GBM", "CAT", "XGB"]
  excluded_model_types: null # ["KNN", "RF", "XT", "NN_TORCH"]
  preset: null # Set to null to determine preset based on training set size
  dynamic_stacking: false
  num_bag_folds: null
  num_stack_levels: null
  save_bag_folds: true
  refit_full: false
  set_best_to_refit_full: false
  cv_fit_time_limit: 12 # Hours
  full_fit_time_limit: 12 # Hours
  feature_importance: true
  FI_time_limit: 3 # Hours
  FI_num_shuffle_sets: 10

models:
  dir: models
  dir_fp: models/try6_q95_stg_pow-xf_1km  # Full path to models directory

aoa:
  dir: aoa
  
predict:
  dir: predict
  geos:
    n_workers: 1
    batches: 8
  pylos:
    n_workers: 1
    batches: 24

cov:
  dir: cov
  
public:
  destination: "both"
  local_dir: final
  sftp_dir: PANOPS/cit-sci-traits/trait_maps

analysis:
  dir: results
  multires_results_fn: all_results.parquet
  multires_fi_fn: all_fi.parquet
