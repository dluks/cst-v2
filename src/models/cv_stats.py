import argparse
import pickle
import shutil
from pathlib import Path
from typing import Any

import dask.dataframe as dd
import numpy as np
import pandas as pd
from autogluon.tabular import TabularPredictor
from box import ConfigBox
from dask import compute, delayed
from sklearn import metrics

from src.conf.conf import get_config
from src.conf.environment import log
from src.utils.dask_utils import close_dask, init_dask
from src.utils.dataset_utils import (
    get_cv_splits_dir,
    get_latest_run,
    get_models_dir,
    get_power_transformer_fn,
    get_predict_imputed_fn,
    get_predict_mask_fn,
    get_y_fn,
)
from src.utils.spatial_utils import lat_weights, weighted_pearson_r
from src.utils.trait_utils import get_active_traits, get_trait_number_from_id

TMP_DIR = Path("tmp")


@delayed
def generate_fold_obs_vs_pred(fold_dir: Path, xy: pd.DataFrame) -> pd.DataFrame:
    """Process a single fold of data."""
    predictor = TabularPredictor.load(str(fold_dir))
    pred = pd.DataFrame({"pred": predictor.predict(xy)})
    return pd.concat([xy[["x", "y", "obs"]], pred], axis=1)


def get_stats(
    cv_obs_vs_pred: pd.DataFrame,
    resolution: int | float | None = None,
    wt_pearson: bool = False,
) -> dict[str, Any]:
    """Calculate statistics for a given DataFrame of observed and predicted values."""
    obs = cv_obs_vs_pred.obs.to_numpy()
    pred = cv_obs_vs_pred.pred.to_numpy()

    r2 = metrics.r2_score(obs, pred)
    pearsonr = cv_obs_vs_pred[["obs", "pred"]].corr().iloc[0, 1]
    pearsonr_wt = None

    if wt_pearson and resolution is not None:
        pearsonr_wt = weighted_pearson_r(
            cv_obs_vs_pred.set_index(["y", "x"]),
            lat_weights(cv_obs_vs_pred.y.unique(), resolution),
        )
    root_mean_squared_error = metrics.root_mean_squared_error(obs, pred)
    norm_root_mean_squared_error = root_mean_squared_error / (
        cv_obs_vs_pred.obs.quantile(0.99) - cv_obs_vs_pred.obs.quantile(0.01)
    )
    mean_squared_error = np.mean((obs - pred) ** 2)
    mean_absolute_error = metrics.mean_absolute_error(obs, pred)
    median_absolute_error = metrics.median_absolute_error(obs, pred)

    return {
        "r2": r2,
        "pearsonr": pearsonr,
        "pearsonr_wt": pearsonr_wt,
        "root_mean_squared_error": root_mean_squared_error,
        "norm_root_mean_squared_error": norm_root_mean_squared_error,
        "mean_squared_error": mean_squared_error,
        "mean_absolute_error": mean_absolute_error,
        "median_absolute_error": median_absolute_error,
    }


def get_fold_wise_stats(
    fold_results: list[pd.DataFrame],
    resolution: int | float | None = None,
    wt_pearson: bool = False,
) -> dict[str, Any]:
    """
    Calculate statistics for each fold and return means and standard deviations.

    Parameters
    ----------
    fold_results : list[pd.DataFrame]
        List of DataFrames, one per fold, each containing obs/pred columns.
    resolution : int | float | None
        Resolution for weighted Pearson correlation calculation.
    wt_pearson : bool
        Whether to calculate weighted Pearson correlation.

    Returns
    -------
    dict[str, Any]
        Dictionary containing mean and std for each metric across folds.
    """
    fold_stats = []

    for fold_df in fold_results:
        stats = get_stats(fold_df, resolution=resolution, wt_pearson=wt_pearson)
        fold_stats.append(stats)

    # Convert to DataFrame for easier calculation
    fold_stats_df = pd.DataFrame(fold_stats)

    # Calculate means and standard deviations across folds
    result = {}
    for metric in fold_stats_df.columns:
        # Skip None values (e.g., pearsonr_wt when not calculated)
        values = fold_stats_df[metric].dropna()
        if len(values) > 0:
            result[f"{metric}_mean"] = float(values.mean())
            result[f"{metric}_std"] = float(values.std())
        else:
            result[f"{metric}_mean"] = None
            result[f"{metric}_std"] = None

    return result


def load_x() -> pd.DataFrame:
    """Load X data for a given trait set."""
    tmp_x_path = TMP_DIR / "cv_stats" / "x.parquet"

    if tmp_x_path.exists():
        log.info("Found cached X data. Loading...")
        return pd.read_parquet(tmp_x_path)

    client, _ = init_dask(dashboard_address=get_config().dask_dashboard)

    x_mask = dd.read_parquet(get_predict_mask_fn())
    x_imp = dd.read_parquet(get_predict_imputed_fn())

    xy = (
        dd.read_parquet(get_y_fn(), columns=["x", "y", "source"])
        .query("source == 's'")
        .drop(columns=["source"])
    )

    x_imp_trait = (
        dd.merge(x_imp, xy, how="inner", on=["x", "y"]).compute().set_index(["y", "x"])
    )
    mask_trait = (
        dd.merge(x_mask, xy, how="inner", on=["x", "y"]).compute().set_index(["y", "x"])
    )

    close_dask(client)

    x_trait_masked = x_imp_trait.mask(mask_trait)
    tmp_x_path.parent.mkdir(parents=True, exist_ok=True)
    x_trait_masked.to_parquet(tmp_x_path)
    return x_trait_masked


def load_y(trait_id: str) -> pd.DataFrame:
    """Load Y data for a given trait set."""
    y = (
        dd.read_parquet(get_y_fn(), columns=["x", "y", trait_id, "source"])
        .query("source == 's'")
        .merge(
            dd.read_parquet(get_cv_splits_dir() / f"{trait_id}.parquet"),
            how="inner",
            on=["x", "y"],
        )[["y", "x", trait_id, "fold"]]
        .dropna()
    )

    return y.compute().set_index(["y", "x"])


def load_xy(x: pd.DataFrame, trait_id: str) -> pd.DataFrame:
    """Load X and Y data for a given trait set."""
    y = load_y(trait_id)
    return x.join(y, how="inner").reset_index().rename({trait_id: "obs"}, axis=1)


def cli() -> argparse.Namespace:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser()
    parser.add_argument("-d", "--debug", action="store_true", help="Run in debug mode.")
    parser.add_argument(
        "-f", "--fold-results", action="store_true", help="Include fold results."
    )
    parser.add_argument(
        "-r", "--recompute", action="store_true", help="Recompute stats."
    )
    parser.add_argument(
        "-p", "--persist", action="store_true", help="Persist temp. X data."
    )
    return parser.parse_args()


def main(args: argparse.Namespace | None = None, cfg: ConfigBox | None = None) -> None:
    """
    Main function for generating spatial CV trait statistics.
    """
    if args is None:
        args = cli()
    if cfg is None:
        cfg = get_config()

    models_dir = get_models_dir() / "debug" if args.debug else get_models_dir()
    trait_sets = ["splot", "splot_gbif", "gbif"]
    valid_traits = get_active_traits(cfg)

    log.info("Loading X data...")
    x = load_x()
    for trait_dir in models_dir.iterdir():
        if not trait_dir.is_dir():
            continue

        if trait_dir.stem not in valid_traits:
            log.info("Skipping trait: %s", trait_dir.stem)
            continue

        trait_id = trait_dir.stem

        for trait_set in trait_sets:
            log.info("Processing trait: %s for %s", trait_id, trait_set)
            ts_dir = get_latest_run(trait_dir / cfg.train.arch) / trait_set
            if not ts_dir.exists():
                log.error("Skipping trait set: %s", trait_set)
                continue

            results_path = Path(ts_dir, cfg.train.eval_results)
            old_path = results_path.with_name(
                f"{results_path.stem}_old{results_path.suffix}"
            )
            if not results_path.exists():
                raise FileNotFoundError(f"Results file not found: {results_path}")

            if results_path.exists() and old_path.exists():
                if not args.recompute:
                    log.info("Found existing stats. Skipping...")
                    continue

                log.info("Found existing stats but recompute is True. Recomputing...")
                results_path.unlink()
                old_path.rename(results_path)

            log.info("Joining X and Y data...")
            trait_df = load_xy(x, trait_id)

            fold_dirs = [d for d in Path(ts_dir, "cv").iterdir() if d.is_dir()]
            fold_ids = [fold_dir.stem.split("_")[-1] for fold_dir in fold_dirs]

            log.info("Splitting folds...")
            fold_dfs = [
                trait_df.query(f"fold == {fold_id}")
                .drop(columns=["fold"])
                .reset_index(drop=True)
                for fold_id in fold_ids
            ]

            delayed_results = [
                generate_fold_obs_vs_pred(fold_dir, fold_df)
                for fold_dir, fold_df in zip(fold_dirs, fold_dfs)
            ]
            log.info("Computing CV predictions...")
            coll = compute(*delayed_results)

            log.info("Concatenating predictions...")
            cv_obs_vs_pred = pd.concat(coll, ignore_index=True)

            # Keep individual fold results for fold-wise statistics
            fold_results = list(coll) if args.fold_results else None

            log.info("Writing results to disk...")
            cv_obs_vs_pred_path = Path(ts_dir, "cv_obs_vs_pred.parquet")
            if cv_obs_vs_pred_path.exists():
                cv_obs_vs_pred_path.unlink()
            cv_obs_vs_pred.to_parquet(cv_obs_vs_pred_path)

            log.info("Calculating stats...")
            all_stats = pd.DataFrame()
            pearsonr_wt = cfg.crs == "EPSG:4326"
            cv_obs_vs_pred_trans = None
            fold_results_trans = None

            # Back-transform if training data was log-transformed
            if cfg.trydb.interim.transform == "log":
                if "ln" in trait_id.split("_"):
                    log.info(
                        "Log-transformed trait detected. Back-transforming prior to "
                        "stats calculation..."
                    )
                    cv_obs_vs_pred_trans = cv_obs_vs_pred.copy()

                    if args.fold_results:
                        fold_results_trans = [fold.copy() for fold in fold_results]

                    cv_obs_vs_pred = cv_obs_vs_pred.assign(
                        obs=np.expm1(cv_obs_vs_pred.obs),
                        pred=np.expm1(cv_obs_vs_pred.pred),
                    )
                    if args.fold_results:
                        fold_results = [
                            fold.assign(
                                obs=np.expm1(fold.obs),
                                pred=np.expm1(fold.pred),
                            )
                            for fold in fold_results
                        ]
            # Back-transform if training data was power-transformed
            elif cfg.trydb.interim.transform == "power":
                with open(get_power_transformer_fn(cfg), "rb") as f:
                    pt = pickle.load(f)

                log.info("Inverse transforming Y data...")
                cv_obs_vs_pred_trans = cv_obs_vs_pred.copy()
                if args.fold_results:
                    fold_results_trans = [fold.copy() for fold in fold_results]

                trait_num = get_trait_number_from_id(trait_id)
                feature_nums = np.array(
                    [get_trait_number_from_id(f) for f in pt.feature_names_in_]
                )
                ft_id = np.where(feature_nums == trait_num)[0][0]

                # Transform overall results
                inv_obs = pt.inverse_transform(
                    pd.DataFrame(columns=pt.feature_names_in_)
                    .assign(**{f"X{trait_num}": cv_obs_vs_pred.obs})
                    .fillna(0)
                )[:, ft_id]

                inv_pred = pt.inverse_transform(
                    pd.DataFrame(columns=pt.feature_names_in_)
                    .assign(**{f"X{trait_num}": cv_obs_vs_pred.pred})
                    .fillna(0)
                )[:, ft_id]

                cv_obs_vs_pred = cv_obs_vs_pred.assign(
                    obs=inv_obs, pred=inv_pred
                ).dropna()

                if args.fold_results:
                    # Transform fold results
                    transformed_folds = []
                    for fold in fold_results:
                        fold_inv_obs = pt.inverse_transform(
                            pd.DataFrame(columns=pt.feature_names_in_)
                            .assign(**{f"X{trait_num}": fold.obs})
                            .fillna(0)
                        )[:, ft_id]

                        fold_inv_pred = pt.inverse_transform(
                            pd.DataFrame(columns=pt.feature_names_in_)
                            .assign(**{f"X{trait_num}": fold.pred})
                            .fillna(0)
                        )[:, ft_id]

                        transformed_folds.append(
                            fold.assign(obs=fold_inv_obs, pred=fold_inv_pred).dropna()
                        )

                    fold_results = transformed_folds

            log.info("Calculating overall stats on non-transformed data...")
            try:
                stats_overall = get_stats(
                    cv_obs_vs_pred,
                    cfg.target_resolution,
                    wt_pearson=pearsonr_wt,
                )
            except ValueError as e:
                log.error("Error calculating stats on non-transformed data: %s", e)
                log.error(
                    "NaNs present in obs or pred: %s", cv_obs_vs_pred.isna().sum()
                )
                raise e

            if args.fold_results:
                log.info("Calculating fold-wise stats on non-transformed data...")
                stats_foldwise = get_fold_wise_stats(
                    fold_results,
                    cfg.target_resolution,
                    wt_pearson=pearsonr_wt,
                )
                log.info("Combining overall and fold-wise statistics...")
                stats = {**stats_overall, **stats_foldwise}
            else:
                stats = stats_overall

            log.info("Calculating overall stats on transformed data...")
            if cv_obs_vs_pred_trans is not None:
                stats_tr_overall = get_stats(
                    cv_obs_vs_pred_trans,
                    cfg.target_resolution,
                    wt_pearson=pearsonr_wt,
                )

                if args.fold_results:
                    log.info("Calculating fold-wise stats on transformed data...")
                    stats_tr_foldwise = get_fold_wise_stats(
                        fold_results_trans,
                        cfg.target_resolution,
                        wt_pearson=pearsonr_wt,
                    )
                    stats_tr = {**stats_tr_overall, **stats_tr_foldwise}
                else:
                    stats_tr = stats_tr_overall

                all_stats = pd.concat(
                    [
                        pd.DataFrame(stats, index=[0]).assign(transform="none"),
                        pd.DataFrame(stats_tr, index=[0]).assign(
                            transform=cfg.trydb.interim.transform
                        ),
                    ],
                    ignore_index=True,
                )
            else:
                all_stats = pd.DataFrame(stats, index=[0]).assign(transform="none")

            log.info("Writing stats to disk...")
            results_path.rename(old_path)
            all_stats.to_csv(results_path, index=False)

    if not args.persist:
        log.info("Cleaning up temporary files...")
        shutil.rmtree(TMP_DIR)


if __name__ == "__main__":
    main()
