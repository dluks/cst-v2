{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Species Name Harmonization Using World Flora Online (WFO)\n",
        "\n",
        "## Background\n",
        "\n",
        "When working with ecological datasets from multiple sources, species names often vary due to:\n",
        "- Different taxonomic authorities and naming conventions\n",
        "- Synonyms and outdated nomenclature\n",
        "- Spelling variations and author citations\n",
        "- Subspecies, varieties, and cultivars vs. species-level names\n",
        "\n",
        "The World Flora Online (WFO) Plant Name Portal provides a comprehensive, standardized reference for vascular plant nomenclature. By matching species names against WFO before joining datasets, we can ensure taxonomic consistency and maximize the overlap between datasets.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load two datasets with species names\n",
        "2. Use the WFO matching API to standardize species names\n",
        "3. Join the datasets using harmonized nomenclature\n",
        "4. Evaluate the quality and success rate of the matching process\n",
        "\n",
        "## Scientific Context\n",
        "\n",
        "Taxonomic name standardization is crucial for:\n",
        "- **Trait synthesis**: Combining functional trait data from multiple databases\n",
        "- **Biogeographic analysis**: Linking occurrence records with trait measurements\n",
        "- **Comparative ecology**: Ensuring species-level comparisons use consistent nomenclature\n",
        "- **Conservation assessment**: Accurate species identification for threat status evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Any\n",
        "\n",
        "# Import our WFO matching utilities\n",
        "from src.utils.wfo_matching import (\n",
        "    WFOMatchingAPI,\n",
        "    harmonize_species_names,\n",
        "    harmonize_and_join_tables,\n",
        "    get_match_quality_report\n",
        ")\n",
        "from src.utils.trait_utils import clean_species_name\n",
        "from src.conf.environment import log\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Example Datasets\n",
        "\n",
        "For demonstration purposes, we'll create two mock datasets with overlapping but differently formatted species names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create example dataset 1: Trait data with some naming variations\n",
        "trait_data = pd.DataFrame({\n",
        "    'species': [\n",
        "        'Quercus alba',           # Standard binomial\n",
        "        'Acer saccharum',         # Standard binomial\n",
        "        'Pinus strobus L.',       # With author\n",
        "        'Fagus grandifolia',      # Standard binomial\n",
        "        'Betula papyrifera',      # Standard binomial\n",
        "        'Tsuga canadensis (L.) Carri√®re',  # With full author citation\n",
        "        'Abies balsamea',         # Standard binomial\n",
        "        'Picea rubens',           # Standard binomial\n",
        "        'Thuja occidentalis',     # Standard binomial\n",
        "        'Ulmus americana',        # Standard binomial\n",
        "    ],\n",
        "    'leaf_area_cm2': [45.2, 78.3, 12.4, 56.7, 34.1, 8.9, 15.2, 6.7, 3.4, 62.5],\n",
        "    'wood_density_g_cm3': [0.68, 0.63, 0.35, 0.64, 0.55, 0.40, 0.37, 0.41, 0.31, 0.46],\n",
        "    'height_m': [25.3, 28.7, 35.2, 30.1, 22.4, 28.9, 18.6, 25.1, 15.2, 24.8]\n",
        "})\n",
        "\n",
        "# Create example dataset 2: Occurrence data with different naming conventions\n",
        "occurrence_data = pd.DataFrame({\n",
        "    'scientific_name': [\n",
        "        'Quercus alba L.',        # With author\n",
        "        'Acer saccharum Marshall', # With different author format\n",
        "        'Pinus strobus',          # Without author\n",
        "        'Fagus grandifolia Ehrh.', # With author\n",
        "        'Betula papyrifera Marshall', # With author\n",
        "        'Tsuga canadensis',       # Without author\n",
        "        'Abies balsamea (L.) Mill.', # With author\n",
        "        'Picea rubens Sarg.',     # With author\n",
        "        'Thuja occidentalis L.',  # With author\n",
        "        'Populus tremuloides',    # Different species not in trait data\n",
        "        'Fraxinus americana',     # Different species not in trait data\n",
        "    ],\n",
        "    'latitude': [45.2, 44.8, 46.1, 45.7, 47.2, 45.9, 46.8, 45.4, 46.2, 44.9, 45.1],\n",
        "    'longitude': [-75.3, -74.2, -76.8, -75.9, -78.1, -76.4, -77.2, -75.8, -76.7, -74.8, -75.6],\n",
        "    'abundance': [12, 8, 15, 6, 23, 11, 9, 18, 7, 14, 5]\n",
        "})\n",
        "\n",
        "print(\"Example datasets created:\")\n",
        "print(f\"\\nTrait data ({len(trait_data)} species):\")\n",
        "print(trait_data.head())\n",
        "print(f\"\\nOccurrence data ({len(occurrence_data)} species):\")\n",
        "print(occurrence_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WFO-Based Species Name Harmonization\n",
        "\n",
        "Now let's use the World Flora Online API to standardize the species names and improve the match rate.\n",
        "\n",
        "**Note**: This example shows the workflow with mock data. In practice, you would replace this with your actual datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize WFO API client\n",
        "# Note: In production, you may want to adjust rate_limit_delay based on API limits\n",
        "wfo_client = WFOMatchingAPI(rate_limit_delay=0.5)  # 0.5 second delay between requests\n",
        "\n",
        "# Create cache directory\n",
        "cache_dir = Path(\"wfo_cache\")\n",
        "cache_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Perform harmonized join in one step\n",
        "print(\"Harmonizing species names and joining tables...\")\n",
        "joined_data = harmonize_and_join_tables(\n",
        "    df1=trait_data,\n",
        "    df2=occurrence_data,\n",
        "    species_col1='species',\n",
        "    species_col2='scientific_name',\n",
        "    join_type='inner',  # Only keep species present in both datasets\n",
        "    api_client=wfo_client,\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "print(f\"\\nJoin Results:\")\n",
        "print(f\"  Original trait data: {len(trait_data)} species\")\n",
        "print(f\"  Original occurrence data: {len(occurrence_data)} species\")\n",
        "print(f\"  Joined data: {len(joined_data)} species\")\n",
        "print(f\"  Success rate: {100*len(joined_data)/min(len(trait_data), len(occurrence_data)):.1f}%\")\n",
        "\n",
        "print(f\"\\nJoined dataset preview:\")\n",
        "print(joined_data[['species_harmonized', 'leaf_area_cm2', 'latitude', 'longitude']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage with Your Data\n",
        "\n",
        "To use this workflow with your actual datasets, follow these steps:\n",
        "\n",
        "1. **Replace example data** with your actual DataFrames\n",
        "2. **Specify correct column names** for species in each dataset\n",
        "3. **Set up caching** to avoid repeated API calls\n",
        "4. **Choose appropriate join type** based on your analysis needs\n",
        "\n",
        "### Example with Project Data\n",
        "\n",
        "```python\n",
        "# Load your actual data\n",
        "from src.conf.conf import get_config\n",
        "cfg = get_config()\n",
        "\n",
        "# Load GBIF data\n",
        "gbif_data = pd.read_parquet(\n",
        "    Path(cfg.interim_dir, cfg.gbif.interim.dir, cfg.gbif.interim.matched)\n",
        ")\n",
        "\n",
        "# Load TRY trait data  \n",
        "try_data = pd.read_parquet(get_try_traits_interim_fn())\n",
        "\n",
        "# Harmonize and join\n",
        "harmonized_data = harmonize_and_join_tables(\n",
        "    df1=gbif_data,\n",
        "    df2=try_data,\n",
        "    species_col1='speciesname',\n",
        "    species_col2='speciesname', \n",
        "    join_type='inner',\n",
        "    cache_dir=Path('data/wfo_cache')\n",
        ")\n",
        "```\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "- **Cache results**: Always use `cache_dir` to avoid repeated API calls\n",
        "- **Rate limiting**: Adjust `rate_limit_delay` based on API usage policies\n",
        "- **Quality checks**: Use `get_match_quality_report()` to assess matching success\n",
        "- **Batch processing**: For large datasets, process in smaller chunks\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
